数据获取

网页数据抓取

数据标注

探索数据分析

   画图看模型分布、数据分布

数据清洗

​    用超参数去掉一些outliner的点

数据变化

   normalization

特征工程

   fune-tuning（微调）



决策树

​	bagging随机采样

   gradient boosting tree: 每次训练一个新的树去拟合梯度的负数，就是对训练不好的样本进行重新生成一部分树

线性模型

   sofrmax：概率化

随机梯度下降

  小批量梯度下降

多层感知机

  非线性模型，多层模型  

  多个全连接层堆起来，中间通过激活层得到一些非线性新的模型

  H: 隐藏层

卷积神经网络

  特殊的全连接层，能高效抓取空间信息

循环神经网络

  时序上把过去的信息放到现在，加进来一条全连接层，加进来一条额外的边

评估指标

​	  准确率：正确的预测比例

​	  精确度(P)：对类A的预测准确率

​	  召回率(R)：预测是类A，且真的是类A的概率

​	  F1分数：平衡精确度和召回率： 2p*r / (p+r)

过拟合和欠拟合

 	方差和偏差

Bagging

 	n个模型结果取平均或者投票(分类)

Stacking

​	不同种类的模型融合起来

模型调参	

超参数优化

   随机搜索

网格架构搜索

  NAS自动化

深度神经网络架构

​	批量归一化

迁移学习

​	对比较好的预训练的模型(通常认为有比较好的泛化性)进行微调

​	编码器：特征提取器

 	解码器：可能是一个简单的线性分类器

 	微调：架构和预训练模型一致

​    初始化特征提取器和预训练模型一致

​     最后一层，输出层也就是解码器用的随机。固定一些层，选择最后几层进行微调

​    但是需要限制时间和次数(搜索半径)，防止记住数据集，也就是过拟合，这也就是为什么叫微调

NIP中的微调

​	bert：带掩码的词预测，编码器

​		bert微调：构造最后一层输出 

​    gpt: transform解码器

​    T5: 基于transform编码器和解码器的架构



  

​	![image-20231214230936329](C:/Users/24188/AppData/Roaming/Typora/typora-user-images/image-20231214230936329.png)

![image-20231214231037140](C:/Users/24188/AppData/Roaming/Typora/typora-user-images/image-20231214231037140.png)